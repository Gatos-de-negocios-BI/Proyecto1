{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import nltk\n",
    "import contractions\n",
    "import inflect\n",
    "import re, string\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import pickle as pkl\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "from datetime import datetime\n",
    "from sklearn.base import BaseEstimator, TransformerMixin \n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextPreprocessor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        print(\"TextPreprocessor initialized\")\n",
    "        self.stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        print(\"Fitting TextPreprocessor...\")\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X, y=None):\n",
    "        print(\"Transforming text...\")\n",
    "        return self.preprocess(X)\n",
    "        \n",
    "    def preprocess(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        print(\"Preprocessing text...\")\n",
    "        # convert series to dataframe\n",
    "        df = pd.DataFrame(df)\n",
    "        print(\"dataframe columns: \", df.columns)\n",
    "        df['text'] = df['text'].str.encode('ascii', 'ignore').str.decode('ascii')\n",
    "        df['no_constractions'] = df['text'].apply(lambda x: [contractions.fix(word) for word in x.split()])\n",
    "        df['text'] = [' '.join(map(str, l)) for l in df['no_constractions']]\n",
    "        df['tokenized'] = df['text'].apply(nltk.word_tokenize)\n",
    "        df['tokenized'] = df['tokenized'].apply(lambda x: [word.lower() for word in x])\n",
    "        punc = string.punctuation\n",
    "        df['tokenized'] = df['tokenized'].apply(lambda x: [word for word in x if word not in punc])\n",
    "        \n",
    "        nltk.download('stopwords')\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        df['tokenized'] = df['tokenized'].apply(lambda x: [word for word in x if word not in stop_words])\n",
    "        df['tokenized_str'] = [' '.join(map(str,l)) for l in df['tokenized']]\n",
    "        df_clean = df[['tokenized_str']]\n",
    "        # rename tokenized_str to text\n",
    "        df_clean.rename(columns={'tokenized_str': 'text'}, inplace=True)\n",
    "        return df_clean\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TextPreprocessor initialized\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('preprocessor', TextPreprocessor()),\n",
    "    ('vectorizer', TfidfVectorizer(tokenizer=nltk.TweetTokenizer.tokenize, \n",
    "                                   stop_words=(set(stopwords.words('english')).union(['4661', 'meeeeeeeeeeee', 'ja', '01457654035', 'reaally', '3624', '3904512441', 'mesooo', 'ان فرع', ''])))),\n",
    "    ('classifier', MLPClassifier(verbose=True, early_stopping=True))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta = \"../data/SuicidiosProyecto.csv\"\n",
    "data = pd.read_csv(ruta, encoding=\"utf-8\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>173271</th>\n",
       "      <td>i want to destroy myselffor once everything wa...</td>\n",
       "      <td>suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336321</th>\n",
       "      <td>I kinda got behind schedule with learning for ...</td>\n",
       "      <td>non-suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256637</th>\n",
       "      <td>I'm just not sure anymoreFirst and foremost: I...</td>\n",
       "      <td>suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303772</th>\n",
       "      <td>please give me a reason to liveThats too much ...</td>\n",
       "      <td>suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293747</th>\n",
       "      <td>27f struggling to find meaning moving forwardI...</td>\n",
       "      <td>suicide</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         text        class\n",
       "Unnamed: 0                                                                \n",
       "173271      i want to destroy myselffor once everything wa...      suicide\n",
       "336321      I kinda got behind schedule with learning for ...  non-suicide\n",
       "256637      I'm just not sure anymoreFirst and foremost: I...      suicide\n",
       "303772      please give me a reason to liveThats too much ...      suicide\n",
       "293747      27f struggling to find meaning moving forwardI...      suicide"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(data['text'], data['class'], test_size=0.3, random_state=28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting TextPreprocessor...\n",
      "Transforming text...\n",
      "Preprocessing text...\n",
      "dataframe columns:  Index(['text'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "pipeline.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = pipeline.predict(x_train)\n",
    "pred_test = pipeline.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_train = confusion_matrix(y_train, pred_train)\n",
    "cm_test = confusion_matrix(y_test, pred_test)\n",
    "cm_train_norm = confusion_matrix(y_train, pred_train, normalize='true')\n",
    "cm_test_norm = confusion_matrix(y_test, pred_test, normalize='true')\n",
    "\n",
    "fig, ax = plt.subplots(nrows=2, ncols=2, figsize=(20, 20))\n",
    "ax[0, 0].set_title('Matriz de confusión de entrenamiento')\n",
    "ax[0, 1].set_title('Matriz de confusión de prueba')\n",
    "ax[1, 0].set_title('Matriz de confusión normalizada de entrenamiento')\n",
    "ax[1, 1].set_title('Matriz de confusión normalizada de prueba')\n",
    "disp_train = ConfusionMatrixDisplay(confusion_matrix=cm_train)\n",
    "disp_test = ConfusionMatrixDisplay(confusion_matrix=cm_test)\n",
    "disp_train_norm = ConfusionMatrixDisplay(confusion_matrix=cm_train_norm)\n",
    "disp_test_norm = ConfusionMatrixDisplay(confusion_matrix=cm_test_norm)\n",
    "disp_train.plot(ax=ax[0, 0])\n",
    "disp_test.plot(ax=ax[0, 1])\n",
    "disp_train_norm.plot(ax=ax[1, 0])\n",
    "disp_test_norm.plot(ax=ax[1, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rutaPipeline =  \"pipeline.pkl\"\n",
    "with open(rutaPipeline, 'wb') as file:\n",
    "    pkl.dump(pipeline, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
